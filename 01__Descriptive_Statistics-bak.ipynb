{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src='img/ms_logo.jpeg' width=30% height=30%></center>\n",
    "<center><h1>Descriptive Statistics</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson, we'll clean and analyze the Titanic data set, and see if descriptive statistics can tell us anything interesting about the data set.  Along the way, we'll gain hands-on experience with industry-standard tools such as the `pandas` library in python. \n",
    "\n",
    "#### About the Data Set.  \n",
    "\n",
    "The Titanic sank after hitting an iceberg the night of May 31st, 1911.  1503 people died--only 705 survived (could have been 706, but some people are door hogs).  \n",
    "\n",
    "<img src='http://4.bp.blogspot.com/-QZUM4Q23E3c/UJ7WFXdJABI/AAAAAAAAAXk/ityxfFzjpPE/w1200-h630-p-k-no-nu/titanic1.jpg' height=50% width=50%>\n",
    "\n",
    "\n",
    "The Titanic dataset is often used as an introduction to data analysis, especially for those interested in machine learning. Because we know who survived and who didn't, we can use the data on passengers to explore, look for trends that affect survival rate, and maybe even make some predictions on which passengers survived by looking at their data.   Today, we'll explore the Titanic dataset and get some real-world practice with cleaning and manipulating data.  \n",
    "\n",
    "#### Pandas--Favorite Tool of Data Scientists \n",
    "\n",
    "<img src='https://media.giphy.com/media/aUhEBE0T8XNHa/giphy.gif' height=25% width=25%>\n",
    "\n",
    "For data processing in Python, you can't beat the `pandas` library.  Pandas is used for creating dataframes, which are reminiscent of tables or spreadsheets, but much more powerful and easy to use.  Pandas provides a clean, easy-to-use API for reading, manipulating, sorting, and slicing data.  \n",
    "\n",
    "#### Learning Goals\n",
    "\n",
    "In this exercise, we have the following goals:\n",
    "\n",
    "1.  Use pandas to read-in and manipulate data.\n",
    "1.  Explore strategies for detecting outliers and dealing with missing (NaN) values\n",
    "1.  Answer questions about our data set using descriptive statistics.\n",
    "1.  Use pandas to slice our dataframe into smaller dataframes based on conditional logic (for instance, all female survivors under a certain age)\n",
    "\n",
    "**Let's get started!**\n",
    "\n",
    "(To execute any cell, press SHIFT + ENTER or press the 'Run' button on the toolbar at the top.)\n",
    "\n",
    "We'll start by importing pandas and setting an alias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll be using pandas a lot, so let's alias it to the name 'pd' to save ourselves some keystrokes\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll want to read in our dataset from the from the the 'datasets' folder in this directory.  Did you know jupyter notebooks can also use terminal commands in code cells?  Just put a '%' sign before the command and it works the same as in the terminal.  For instance, if you wanted to list all the items contained in this current directory, you would just type `%ls`!  Try it below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type % ls and run this cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data set is contained within the `datasets` folder, and is called `titanic.csv`.  You may have some experience reading data in manually using the `open` keyword in python.  With large/complex datasets, this method can get tedious very quickly.  However, `pandas` makes this a simple task!\n",
    "\n",
    "**TASK: Read in the titanic.csv file using the pd.read_csv( ) method in pandas.**\n",
    "\n",
    "HINT:  You'll still need to pass the method the correct arguments--in order to get this right, You'll need the documentation for this method.  You can find that [here](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html).  \n",
    "\n",
    "Alternatively, you can just type the method name with a question mark instead of parentheses to open a method's docs right here in the notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need the docs? try typing pd.read_csv? \n",
    "\n",
    "df = None   # store the newly created dataframe in this variable\n",
    "df   # this will display the contents of df (the dataframe containing all our data, truncated for readability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! With the pandas library, importing large datasets becomes really, really easy.  We can also use it to examine the data, and manipulate the dataset very easily. Before we can make sense of the data, we should probably have a feel for what each column means.  Here's the **Data Dictionary** explaining what each column and value actually means:\n",
    "\n",
    "\n",
    "<center><h2>Data Dictionary</h2></center>\n",
    "\n",
    "\n",
    "| Variable | Definition                                        | Key                                            |\n",
    "|----------|---------------------------------------------------|------------------------------------------------|\n",
    "| Survived | Survival                                          | 0 = No, 1 = Yes                                |\n",
    "| Pclass   | Ticket Class (proxy for socio-economic status)    | 1 = 1st, 2 = 2nd, 3 = 3rd                      |\n",
    "| Sex      | Sex                                               |                                                |\n",
    "| Age      | Age (in years)                                    |                                                |\n",
    "| SibSp    | # of siblings and/or spouses also aboard          |                                                |\n",
    "| Parch    | # of parents / children also aboard               |                                                |\n",
    "| Ticket   | Ticket number                                     |                                                |\n",
    "| Fare     | Passenger fare (how much their ticket cost)       |                                                |\n",
    "| Cabin    | Cabin number                                      |                                                |\n",
    "| Embarked | Port of Embarkation (where they boarded the ship) | C = Cherbourg, Q = Queenstown, S = Southampton |\n",
    "\n",
    "Let's get the basic descriptive statistics to see what we can figure out about this dataset.  \n",
    "\n",
    "**TASK: Run the dataframe's .describe( ) command.  **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run df.describe().  What does each cell in the table mean?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also call `.describe()` on individual columns (a single column of data is called a pandas _series_).  For instance, if we wanted to see the summary statistics on the _SibSp_ column, we would type `df[\"SibSp\"].describe()`\n",
    "\n",
    "See if you can answer the following questions:  \n",
    "\n",
    "1.  How old is the oldest passenger on the titanic?\n",
    "1.  How young is the youngest passenger?\n",
    "1.  What is the average price paid for a ticket?\n",
    "1.  How much did the most expensive ticket cost?\n",
    "1.  How many passengers in the dataset are female?\n",
    "\n",
    "Answers:\n",
    "\n",
    "1.  \n",
    "1.  \n",
    "1.  \n",
    "1.  \n",
    "1.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the .describe() method on the appropriate columns to answer the questions listed above.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h3>Slicing</h3></center>\n",
    "\n",
    "We can also use pandas to 'slice' dataframes, just as we would with a list in python.  However, unlike list slicing in vanilla python, we can slice using conditional logic.  For instance, what if we want to examine a dataframe that only contains the passengers that survived?  Easy-- we just type:\n",
    "\n",
    "<center>`survived_df = df[df[\"Survived\"] == 1]`</center>\n",
    "\n",
    "The syntax for slicing can feel a bit clunky at first, but it will become intuitive with practice.  \n",
    "\n",
    "If you want to slice on multiple conditions, you can do that too!  Just make sure each condition is wrapped in a set of parentheses.  For instance, if we wanted to grab a dataframe filled only when men that survived, we would use:\n",
    "<br>\n",
    "<br>\n",
    "<center>`df[(df['Survived'] == 1) & (df['Sex'] == 'male')]`</center>\n",
    "\n",
    "\n",
    "**TASK: Use your knowledge of conditional slicing to answer the following questions:**\n",
    "\n",
    "(HINT: Don't forget about the `.describe()` method!)\n",
    "\n",
    "1.  How many men survived?\n",
    "1.  What is the average age of male passengers that survived?\n",
    "1.  How many female passengers under the age of 30 did not survive?\n",
    "1.  What was the most expensive ticket bought by answer passenger from Cherbourg that did NOT survive?\n",
    "1.  Of all surviving passengers from Southampton, how many passengers paid between \\$216 and \\$676.50 for their ticket? \n",
    "\n",
    "**Answers:**\n",
    "\n",
    "1.  \n",
    "1.  \n",
    "1.  \n",
    "1.  \n",
    "1.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use your knowledge of conditional slicing to answer the questions above!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:MS-ML-P3]",
   "language": "python",
   "name": "conda-env-MS-ML-P3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
